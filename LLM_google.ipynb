{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec3102c",
   "metadata": {},
   "source": [
    "# LLM post-processing for OCR text\n",
    "\n",
    "- Uses a free Hugging Face model (google/flan-t5-small) for cleaning and Q&A over OCR output.\n",
    "\n",
    "- Install deps if needed: `pip install -q transformers accelerate sentencepiece`.\n",
    "\n",
    "- Store enhanced text in `enhanced_context`; reuse it to answer multiple user queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8138b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afe9ae4d98c4a7faece946ad1c13229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b33fffd1e4496191928ad1e34da9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b47bddb76b4606b009d455033cfe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c4955bba8e4bf7bec611341b930faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5acb56306304b46ba262fe9e8299f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Optional installs (uncomment if not already installed)\n",
    "\n",
    "# %pip install -q transformers accelerate sentencepiece\n",
    "\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Choose a more capable free model (larger = better quality, slower). Examples:\n",
    "\n",
    "#   - google/flan-t5-large  (better than small/base; needs ~3–5GB RAM)\n",
    "\n",
    "#   - google/flan-t5-xl     (stronger; needs ~8–12GB RAM)\n",
    "\n",
    "# Defaulting to flan-t5-large for better accuracy.\n",
    "\n",
    "MODEL_NAME = \"google/flan-t5-large\"\n",
    "\n",
    "DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "\n",
    "\n",
    "# Create a single shared pipeline (reused for cleaning and Q&A)\n",
    "\n",
    "llm = pipeline(\"text2text-generation\", model=MODEL_NAME, tokenizer=MODEL_NAME, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637bba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_ocr_text = \"\"\"--- OCR TEXT ---\n",
    "FakeDoc M.D.\n",
    "HEALTH INTAKE FORM\n",
    "Please fill out the questionnaire carefully. The information you provide will be used to complete\n",
    "your health profile and will be kept confidential.\n",
    "Date: 4 [ 4 : 14\n",
    "d\n",
    "Name: Da Walker DOB: dF | v4 [14 86\n",
    "Address: 24 Barnes Lune City: Josato State: I Zip: 7932\n",
    "Email: Sal}, val ed® Cmatl-t09 Phone #: ie) 17-3938 0\n",
    "Gender: f Marital Status: S14 4 Le Occupation: Sol vure Ta Ancer\n",
    "Referred By: AAA\n",
    "Emergency Contact: = fA_Aaver Emergency Contact Phone: ( 4) 5 ) 334 dt lho\n",
    "Describe your medical concerns (symptoms, diagnoses, etc):\n",
    "Paan A%M®.e Mitas In lwo. wl phy ss\n",
    "a /\n",
    "ALACS Chile S bred\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance OCR text (cleanup + structured extraction) and store for reuse\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Ensure raw_ocr_text exists (paste your OCR output if empty)\n",
    "\n",
    "try:\n",
    "\n",
    "    raw_ocr_text\n",
    "\n",
    "except NameError:\n",
    "\n",
    "    raw_ocr_text = \"\"\"<paste your OCR output here>\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def enhance_text(raw_text: str, max_new_tokens: int = 256) -> str:\n",
    "\n",
    "    prompt = (\n",
    "\n",
    "        \"Clean and normalize this OCR text from a filled form. \"\n",
    "\n",
    "        \"Keep all fields, fix spacing/casing, and remove obvious OCR artifacts only. \"\n",
    "\n",
    "        \"Do NOT invent values. Return the cleaned text.\\n\"\n",
    "\n",
    "        f\"OCR text:\\n{raw_text}\"\\\n",
    "\n",
    "    )\n",
    "\n",
    "    result = llm(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "    return result.strip()\n",
    "\n",
    "\n",
    "\n",
    "FIELD_SCHEMA = {\n",
    "\n",
    "    \"name\": \"\",\n",
    "\n",
    "    \"dob\": \"\",\n",
    "\n",
    "    \"address\": \"\",\n",
    "\n",
    "    \"city\": \"\",\n",
    "\n",
    "    \"state\": \"\",\n",
    "\n",
    "    \"zip\": \"\",\n",
    "\n",
    "    \"phone\": \"\",\n",
    "\n",
    "    \"email\": \"\",\n",
    "\n",
    "    \"gender\": \"\",\n",
    "\n",
    "    \"marital_status\": \"\",\n",
    "\n",
    "    \"occupation\": \"\",\n",
    "\n",
    "    \"emergency_contact_name\": \"\",\n",
    "\n",
    "    \"emergency_contact_phone\": \"\",\n",
    "\n",
    "    \"policy_number\": \"\",\n",
    "\n",
    "    \"date\": \"\",\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def clean_value(text: str) -> str:\n",
    "\n",
    "    # Strip trailing punctuation and obvious leftovers\n",
    "\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip(\" ,;:-\")\n",
    "\n",
    "\n",
    "\n",
    "def heuristic_extract(clean_text: str) -> Dict[str, str]:\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # Stronger regex anchors for names and phones\n",
    "\n",
    "    name_match = re.search(r\"Name[:\\s]+([A-Za-z][A-Za-z\\s.'-]{1,40})\", clean_text, re.IGNORECASE)\n",
    "\n",
    "    dob_match = re.search(r\"DOB[:\\s]+([0-9]{1,2}[\\-/][0-9]{1,2}[\\-/][0-9]{2,4})\", clean_text, re.IGNORECASE)\n",
    "\n",
    "    email_match = re.search(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", clean_text)\n",
    "\n",
    "    phone_match = re.search(r\"Phone[:\\s#]*([+\\d][\\d\\s()\\-]{7,20})\", clean_text, re.IGNORECASE)\n",
    "\n",
    "    if name_match:\n",
    "\n",
    "        out[\"name\"] = clean_value(name_match.group(1))\n",
    "\n",
    "    if dob_match:\n",
    "\n",
    "        out[\"dob\"] = clean_value(dob_match.group(1))\n",
    "\n",
    "    if email_match:\n",
    "\n",
    "        out[\"email\"] = clean_value(email_match.group(0))\n",
    "\n",
    "    if phone_match:\n",
    "\n",
    "        out[\"phone\"] = clean_value(phone_match.group(1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def extract_fields(clean_text: str, max_new_tokens: int = 256) -> Dict[str, str]:\n",
    "\n",
    "    schema_lines = \"\\n\".join([f\"- {k}\" for k in FIELD_SCHEMA.keys()])\n",
    "\n",
    "    prompt = (\n",
    "\n",
    "        \"Extract the following fields from the cleaned OCR form text. \"\n",
    "\n",
    "        \"Respond ONLY as a single-line JSON object with exactly these keys. \"\n",
    "\n",
    "        \"If a field is missing, use an empty string. Do NOT add text outside JSON.\\n\"\n",
    "\n",
    "        f\"Fields:\\n{schema_lines}\\n\"\n",
    "\n",
    "        f\"Clean text:\\n{clean_text}\"\n",
    "\n",
    "    )\n",
    "\n",
    "    result = llm(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "    text = result.strip()\n",
    "\n",
    "    parsed = None\n",
    "\n",
    "    try:\n",
    "\n",
    "        import json\n",
    "\n",
    "        parsed = json.loads(text)\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        parsed = None\n",
    "\n",
    "\n",
    "\n",
    "    fields = {k: \"\" for k in FIELD_SCHEMA.keys()}\n",
    "\n",
    "    if isinstance(parsed, dict):\n",
    "\n",
    "        for k in fields.keys():\n",
    "\n",
    "            if k in parsed and isinstance(parsed[k], str):\n",
    "\n",
    "                fields[k] = clean_value(parsed.get(k, \"\"))\n",
    "\n",
    "    else:\n",
    "\n",
    "        fields[\"raw_extraction\"] = text\n",
    "\n",
    "\n",
    "\n",
    "    # Fill missing with heuristic extraction\n",
    "\n",
    "    heur = heuristic_extract(clean_text)\n",
    "\n",
    "    for k, v in heur.items():\n",
    "\n",
    "        if not fields.get(k):\n",
    "\n",
    "            fields[k] = v\n",
    "\n",
    "    return fields\n",
    "\n",
    "\n",
    "\n",
    "# Run once and keep the enhanced and structured versions for repeated queries\n",
    "\n",
    "enhanced_context = enhance_text(raw_ocr_text)\n",
    "\n",
    "structured_fields = extract_fields(enhanced_context)\n",
    "\n",
    "\n",
    "\n",
    "# Build a QA context that combines structured fields plus cleaned text\n",
    "\n",
    "qa_context = (\n",
    "\n",
    "    \"Structured fields:\\n\" + str(structured_fields) + \"\\n\\n\" + \"Clean text:\\n\" + enhanced_context\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- Enhanced Context ---\\n\", enhanced_context)\n",
    "\n",
    "print(\"\\n--- Structured Fields ---\\n\", structured_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e9666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the customer's name?\n",
      "A: Da Walker DOB: dF | v4 [14 86 Address: 24 Barnes Lune City: Josato State: I Zip: 7932 Email: Sal, val ed® Cmatl-t09 Phone #: ie) 17-3938 0 Gender: f Marital Status: S14 4 Le Occupation: Sol vure Ta Ancer Referred By: AAA Emergency Contact: = fA_Aaver Emergency Contact Phone: ( 4) 5 ) 334 dt lho\n",
      "\n",
      "Q: What is the policy number?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m example_questions:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mA:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43manswer_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36manswer_query\u001b[39m\u001b[34m(question, context, max_new_tokens)\u001b[39m\n\u001b[32m      7\u001b[39m ctx = context \u001b[38;5;129;01mor\u001b[39;00m qa_context\n\u001b[32m      9\u001b[39m prompt = (\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAnswer the user\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms question using only the provided context from a filled form. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m result = \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:191\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    188\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    193\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    194\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    195\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    196\u001b[39m     ):\n\u001b[32m    197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1460\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1461\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1464\u001b[39m         )\n\u001b[32m   1465\u001b[39m     )\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1473\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1475\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:220\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    218\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2566\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2563\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2565\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2566\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2578\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2579\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2580\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2581\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3267\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3264\u001b[39m flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3265\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3267\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3269\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3270\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3271\u001b[39m     model_outputs,\n\u001b[32m   3272\u001b[39m     model_kwargs,\n\u001b[32m   3273\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3274\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1764\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1761\u001b[39m         decoder_attention_mask = decoder_attention_mask.to(\u001b[38;5;28mself\u001b[39m.decoder.first_device)\n\u001b[32m   1763\u001b[39m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1764\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1765\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1774\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1780\u001b[39m sequence_output = decoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1100\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m   1098\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1116\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:737\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    734\u001b[39m     attention_outputs = attention_outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]\n\u001b[32m    736\u001b[39m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m737\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hidden_states.dtype == torch.float16:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:343\u001b[39m, in \u001b[36mT5LayerFF.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[32m    342\u001b[39m     forwarded_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     forwarded_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(forwarded_states)\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:314\u001b[39m, in \u001b[36mT5DenseGatedActDense.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    312\u001b[39m hidden_linear = \u001b[38;5;28mself\u001b[39m.wi_1(hidden_states)\n\u001b[32m    313\u001b[39m hidden_states = hidden_gelu * hidden_linear\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m(hidden_states)\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# See https://github.com/huggingface/transformers/issues/20287\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    320\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.wo.weight, torch.Tensor)\n\u001b[32m    321\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m hidden_states.dtype != \u001b[38;5;28mself\u001b[39m.wo.weight.dtype\n\u001b[32m    322\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.wo.weight.dtype != torch.int8\n\u001b[32m    323\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tsheikh\\Downloads\\Tanveer\\HCL HACKTHON\\HCL_Hackthon\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1951\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1946\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1948\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1949\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1950\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1953\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Query the enhanced context repeatedly\n",
    "\n",
    "\n",
    "\n",
    "def answer_query(question: str, context: str | None = None, max_new_tokens: int = 128) -> str:\n",
    "\n",
    "    ctx = context or qa_context\n",
    "\n",
    "    prompt = (\n",
    "\n",
    "        \"Answer the user's question using only the provided context from a filled form. \"\n",
    "\n",
    "        \"Prefer the structured fields; if a field is empty, you may cite the clean text. \"\n",
    "\n",
    "        \"If the answer is missing, say 'Not found in context.'\\n\"\n",
    "\n",
    "        f\"Context:\\n{ctx}\\n\"\n",
    "\n",
    "        f\"Question: {question}\"\n",
    "\n",
    "    )\n",
    "\n",
    "    result = llm(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0][\"generated_text\"]\n",
    "\n",
    "    return result.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Example queries (edit as needed)\n",
    "\n",
    "example_questions = [\n",
    "\n",
    "    \"What is the customer's name?\",\n",
    "\n",
    "    \"What is the policy number?\",\n",
    "\n",
    "    \"What is the date of birth?\",\n",
    "\n",
    "    \"What is the emergency contact phone?\",\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for q in example_questions:\n",
    "\n",
    "    print(f\"Q: {q}\")\n",
    "\n",
    "    print(\"A:\", answer_query(q))\n",
    "\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
